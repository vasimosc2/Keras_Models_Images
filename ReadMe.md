# ðŸ“¸ Image Recognition Project

This project is designed for efficient image recognition and consists of four key files:

## ðŸ“‚ Project Files
1. **`main.py`** â€“ The main script orchestrating the model's functionality.
2. **`config.json`** â€“ Defines the hyperparameter search space and training configuration.
3. **`Training/train_and_evaluate.py`** â€“ Handles model training and evaluation.
4. **`models/takunet.py`** â€“ Contains the Takunet model architecture.

---

## ðŸ›  `config.json`: Model Configuration
This JSON file dictates the hyperparameters and constraints for training, ensuring optimal model performance within resource limitations.

### ðŸ”¹ **Model Architecture**
- **`stages`** â€“ Number of Takublocks in the model.
- **`filters`** â€“ Filters are small matrices that scan over an image to detect patterns like edges, textures, or shapes. 
                  The number of filters determines how many different features the model can learn at each layer.
                  More filters â†’ The model learns more complex patterns but requires more computation.
                  Fewer filters â†’ Faster training, but might miss some details.
                
- **`kernel_size`** â€“ The kernel size defines the height Ã— width of the small matrix (filter) that moves across the image. 
                      Common sizes include 3Ã—3, 5Ã—5, and 7Ã—7.
                      Smaller kernels (e.g., 3Ã—3) â†’ Better at detecting fine details like edges and textures.
                      Larger kernels (e.g., 5Ã—5, 7Ã—7) â†’ Capture bigger patterns but may miss fine details.

- **`activation`** â€“ Activation function in convolutional layers.
- **`strides`** â€“ Step size for the convolutional filter.
- **`dropout_rate`** â€“ Probability of neuron dropout for overfitting prevention.
- **`num_units`** â€“ Neurons in fully connected (dense) layers.
- **`dense_activation`** â€“ Activation function for dense layers.
- **`num_output_classes`** â€“ Number of classification output classes.

### ðŸ”¹ **Training Parameters**
- **`optimizer`** â€“ Optimization algorithm for training.
- **`loss`** â€“ Loss function (e.g., `categorical_crossentropy` for multi-class classification).

- **`learning_rate`** â€“ The learning rate (LR) controls how much the model updates weights during training.
                        High LR â†’ Model learns fast but might overshoot the optimal point.
                        Low LR â†’ Model learns slowly but might get stuck in local minima.
                        
- **`num_epochs`** â€“  An epoch is one full pass through the entire dataset during training.
                      Too few epochs â†’ The model might underfit (not learn enough patterns).
                      Too many epochs â†’ The model might overfit (memorizing the training data instead of generalizing well to new data).

- **`batch_size`** - Batch size refers to the number of training samples processed before the model updates its weights.
                     Smaller batch sizes â†’ More frequent updates, more generalization, but slower training.
                     Larger batch sizes â†’ Faster training, but may lead to less generalization.

### ðŸ”¹ **Memory Constraints** *(Optimized for Arduino Nano 33 BLE Sense)*
- **`max_ram_consumption`** â€“ Maximum RAM usage (256 KB).
- **`max_flash_consumption`** â€“ Maximum flash memory (1 MB).
- **`data_dtype_multiplier`** â€“ Memory scaling based on data type (`int8`, thus `1`).
- **`model_dtype_multiplier`** â€“ Scaling factor for model precision.

---
This structured configuration ensures streamlined model training while adhering to the hardware constraints of resource-limited environments 
like the **Arduino Nano 33 BLE Sense**. ðŸš€

## Setup

To set up the environment, install the required dependencies:

python3.11 -m venv venv
or
python -m venv venv

```bash
source venv/bin/activate
pip install --upgrade pip
pip install -r requirements.txt

pip freeze